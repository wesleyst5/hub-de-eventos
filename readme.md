# Event Hub Local - Arquitetura Kafka com Proxy, Schema Registry e Billing

Este projeto simula localmente uma arquitetura moderna de Hub de Eventos baseada em Apache Kafka, com proxy autenticado, registro automÃ¡tico de schemas, controle de consumo (billing) e monitoramento via Prometheus e Grafana.

---

## ğŸš€ VisÃ£o Geral

A soluÃ§Ã£o permite mÃºltiplos tenants produzirem e consumirem eventos em tÃ³picos isolados, com controle de acesso via OAuth2/JWT, persistÃªncia dos dados e mÃ©tricas em PostgreSQL, caching em Redis, alÃ©m de dashboards customizados para monitoramento em tempo real.

---

## ğŸ¯ Requisitos Aplicados

### 1. Requisitos Funcionais

- Suporte a mÃºltiplos tenants com tÃ³picos dinÃ¢micos e isolados por tenant.
- ProduÃ§Ã£o e consumo de eventos via proxy autenticado.
- Registro automÃ¡tico de schemas com Confluent Schema Registry.
- AutenticaÃ§Ã£o e autorizaÃ§Ã£o via OAuth2/JWT no proxy.
- Registro detalhado do consumo por tenant e tÃ³pico para billing.
- Armazenamento persistente de logs e mÃ©tricas em PostgreSQL.
- MÃ©tricas em tempo real expostas para Prometheus.
- Dashboards Grafana para visualizaÃ§Ã£o operacional.
- Escalabilidade horizontal para mÃºltiplos tenants e conexÃµes simultÃ¢neas.

### 2. Requisitos NÃ£o Funcionais

- Baixa latÃªncia e alta performance na comunicaÃ§Ã£o proxy-Kafka.
- PersistÃªncia e resiliÃªncia dos dados e mÃ©tricas.
- SeguranÃ§a reforÃ§ada na autenticaÃ§Ã£o e proteÃ§Ã£o dos dados.
- Observabilidade completa via logs estruturados e dashboards.
- Portabilidade via Docker Compose para fÃ¡cil deploy local ou nuvem.
- AutomaÃ§Ã£o de processos via scripts para schema registration e billing.

### 3. Requisitos TÃ©cnicos

- Apache Kafka 7.5.0 e Zookeeper compatÃ­vel.
- Confluent Schema Registry para gerenciamento de schemas.
- PostgreSQL 15 para persistÃªncia de mÃ©tricas e billing.
- Redis 7 para caching de mÃ©tricas e controle rÃ¡pido.
- Proxy em Python (Flask/FastAPI) com integraÃ§Ã£o Kafka e OAuth2.
- MÃ©tricas no formato Prometheus (biblioteca prometheus-client).
- Dashboards prontos para Grafana.
- Scripts auxiliares para automaÃ§Ã£o de tarefas.

### 4. Requisitos de IntegraÃ§Ã£o

- Proxy integra com Kafka via confluent-kafka-python.
- Proxy registra schemas via REST API do Schema Registry.
- Proxy armazena logs e billing no PostgreSQL.
- Proxy usa Redis para caching de mÃ©tricas.
- Prometheus coleta mÃ©tricas do proxy.
- Grafana consome dados do Prometheus para dashboards.
- Suporte para mÃºltiplos tenants com namespace isolado.

### 5. Requisitos de Uso

- Acesso ao proxy via tokens OAuth2/JWT vÃ¡lidos.
- ProduÃ§Ã£o e consumo com identificaÃ§Ã£o clara do tenant.
- Registro automÃ¡tico de schemas no envio da primeira mensagem.
- Billing gerado automaticamente a partir dos logs de consumo.
- Monitoramento contÃ­nuo via Grafana e Prometheus.
- AdministraÃ§Ã£o Kafka via Kafka UI (opcional).

---

## ğŸ“¦ Estrutura do Projeto

```
event-hub-local/
â”‚
â”œâ”€â”€ docker-compose.yml           # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ proxy/                      # CÃ³digo do proxy Python
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ billing.py
â”‚   â”œâ”€â”€ kafka_client.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ register_schemas.py     # Script para registrar schemas automaticamente
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboards/             # Dashboards prontos para Grafana
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml          # ConfiguraÃ§Ã£o do Prometheus
â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ init.sql                # Script para criaÃ§Ã£o das tabelas de billing
â””â”€â”€ redis/                      # ConfiguraÃ§Ãµes padrÃµes do Redis (Docker)
```

---

## âš™ï¸ Como Rodar Localmente

1. Clone o repositÃ³rio.

2. Execute o comando abaixo para subir os serviÃ§os:

```bash
docker-compose up --build
```

3. Acesse os serviÃ§os:

- Kafka Broker: `localhost:9092`
- Schema Registry: `http://localhost:8081`
- Proxy API: `http://localhost:5000`
- Prometheus: `http://localhost:9090`
- Grafana: `http://localhost:3000` (usuÃ¡rio/senha padrÃ£o: admin/admin)

4. Registre schemas automaticamente executando:

```bash
python3 schema/register_schemas.py
```

5. Teste a produÃ§Ã£o e consumo via proxy usando um token OAuth2/JWT vÃ¡lido.

---

## ğŸ“Š Monitoramento e Billing

- O proxy expÃµe mÃ©tricas no formato Prometheus.
- Grafana estÃ¡ configurado para mostrar dashboards de mÃ©tricas por tenant e tÃ³pico.
- Billing Ã© gerado automaticamente a partir dos logs de consumo gravados no PostgreSQL.

---

## ğŸ” SeguranÃ§a

- O proxy exige token JWT vÃ¡lido para todas as operaÃ§Ãµes.
- Dados sÃ£o isolados por tenant para garantir seguranÃ§a multi-tenant.
- VariÃ¡veis sensÃ­veis sÃ£o configuradas via ambiente (Ã© recomendado usar Docker secrets para produÃ§Ã£o).

---

## ğŸ“š ReferÃªncias

- [Apache Kafka](https://kafka.apache.org/)
- [Confluent Schema Registry](https://docs.confluent.io/platform/current/schema-registry/index.html)
- [Prometheus](https://prometheus.io/)
- [Grafana](https://grafana.com/)
- [OAuth2 & JWT](https://oauth.net/2/)
- [Redis](https://redis.io/)
- [PostgreSQL](https://www.postgresql.org/)

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Abra issues ou pull requests para melhorias.

---

**Desenvolvido para fornecer uma arquitetura escalÃ¡vel e segura para hub de eventos multi-tenant com Kafka e monitoramento completo.**

## SugestÃ£o de cÃ¡lculo de custo
   - Custo por mensagem: R$ 0,005
   - Custo por byte: R$ 0,00001
```bash
SELECT
  client_id,
  SUM(mensagens) AS total_mensagens,
  SUM(bytes) AS total_bytes,
  SUM(mensagens)*0.005 AS custo_mensagens,
  SUM(bytes)*0.00001 AS custo_bytes,
  SUM(mensagens)*0.005 + SUM(bytes)*0.00001 AS custo_total
FROM billing
GROUP BY client_id
ORDER BY client_id;
```
